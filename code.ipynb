{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "data = np.load('data.npy', allow_pickle=True)\n",
    "# game_id , resnet(1 x 1024) , vit (1 x 512) , label_name , guess time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Distribution of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.array(data[:, 3])\n",
    "values, counts = np.unique(data_labels, return_counts=True)\n",
    "# plt.figure(figsize=(10, 40))\n",
    "# plt.xlabel('Frequency')\n",
    "# plt.ylabel('Label')\n",
    "# plt.title('Distribution of the various labels')\n",
    "# plt.barh(values, counts)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k, encoder_type, metric):\n",
    "        self.k = k\n",
    "        self.encoder_type = encoder_type\n",
    "        self.metric = metric\n",
    "        self.measure = 'mode'\n",
    "\n",
    "    def get_encoder_type(self):\n",
    "        return self.encoder_type\n",
    "    def set_encoder_type(self,encoder_type):\n",
    "        self.encoder_type = encoder_type\n",
    "\n",
    "    def get_metric(self):\n",
    "        return self.metric\n",
    "    def set_metric(self,metric):\n",
    "        self.metric = metric\n",
    "\n",
    "    def get_k(self): # get method for K\n",
    "        return self.k\n",
    "    def set_k(self,k): # set method for K\n",
    "        self.k = k\n",
    "\n",
    "    def get_measure(self, A):\n",
    "        if self.measure == 'mode':\n",
    "            unique_values, counts = np.unique(np.array(A), return_counts=True)\n",
    "            mode_index = np.argmax(counts)\n",
    "            mode = unique_values[mode_index]\n",
    "            return mode\n",
    "\n",
    "    def get_distance(self, E1, E2):\n",
    "        # print(self.metric)\n",
    "        if self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(np.array(E1) - np.array(E2)))\n",
    "        elif self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum(np.square(np.array(E1) - np.array(E2))))\n",
    "        elif self.metric == 'cosine':\n",
    "            # print(E1.shape)\n",
    "            # print(E2.shape)\n",
    "            return 1-(np.dot(E1[0],E2[0])) / (norm(E1[0]) * norm(E2[0]))\n",
    "        else:\n",
    "            # print(\"Unrecognised\")\n",
    "            raise ValueError(\"Invalid metric\")\n",
    "        \n",
    "    def fit(self, train_embeddings, train_labels, validate_embeddings, validate_labels):\n",
    "        self.train_embeddings = train_embeddings\n",
    "        self.train_labels = train_labels\n",
    "        self.validate_embeddings = validate_embeddings\n",
    "        self.validate_labels = validate_labels\n",
    "\n",
    "    def data_split(self,data):\n",
    "        self.labels = np.array(data[:, 3])\n",
    "        self.embeddings = np.array(data[:,1:3])\n",
    "        self.resnet = np.array(data[:,1])\n",
    "        self.vit = np.array(data[:,2])\n",
    "        num_total_samples = data.shape[0]\n",
    "        num_training_samples = int(num_total_samples * 0.8)\n",
    "        indices = np.array(range(num_total_samples)) # used to check if unshuffled data is giving same results across users\n",
    "        # np.random.shuffle(indices) # permutes the array [0,....n-1] \n",
    "        # indices = np.random.permutation(num_total_samples) \n",
    "        self.indices = indices # saving indices\n",
    "        self.num_training_samples = num_training_samples # saving number of training samples\n",
    "\n",
    "    def evaluate(self, embeddings, true_labels):\n",
    "        predicted_labels = self.predict_array(embeddings)\n",
    "        F1_score = f1_score(true_labels, predicted_labels, average='macro')\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        precision = precision_score(true_labels, predicted_labels, average='macro',zero_division=0)\n",
    "        recall = recall_score(true_labels, predicted_labels, average='macro',zero_division=0)\n",
    "        return F1_score, accuracy, precision, recall\n",
    "\n",
    "    def train(self, encoder_type):\n",
    "        if encoder_type == 'vit':\n",
    "            train_index = self.indices[:self.num_training_samples]\n",
    "            validate_index = self.indices[self.num_training_samples:]\n",
    "            data_train = self.vit[train_index]\n",
    "            data_validate = self.vit[validate_index]\n",
    "            label_train = self.labels[train_index]\n",
    "            label_validate = self.labels[validate_index]\n",
    "            self.fit(data_train, label_train, data_validate, label_validate)\n",
    "        elif encoder_type == 'resnet':\n",
    "            train_index = self.indices[:self.num_training_samples]\n",
    "            validate_index = self.indices[self.num_training_samples:]\n",
    "            data_train = self.resnet[train_index]\n",
    "            data_validate = self.resnet[validate_index]\n",
    "            label_train = self.labels[train_index]\n",
    "            label_validate = self.labels[validate_index]\n",
    "            self.fit(data_train, label_train, data_validate, label_validate)\n",
    "\n",
    "    def predict_sample(self, E):\n",
    "        distances = [self.get_distance(embedding, E) for embedding in self.train_embeddings]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        nearest_index = sorted_indices[:self.k]\n",
    "        nearest_labels = self.train_labels[nearest_index]\n",
    "        classified_label = self.get_measure(nearest_labels)\n",
    "        return classified_label\n",
    "\n",
    "    def predict_array(self, X):\n",
    "        predictions = [self.predict_sample(embeddings) for embeddings in X]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def print_answer(self):\n",
    "        self.data_split(data)\n",
    "        self.train(self.encoder_type)  \n",
    "        F1_score, accuracy, precision, recall = self.evaluate(self.validate_embeddings, self.validate_labels)\n",
    "        print_data = [['Accuracy',accuracy],['Precision',precision],['Recall',recall],['f1_score',F1_score]]\n",
    "        df = pd.DataFrame(print_data,columns=['Measure','Value'])\n",
    "        print(df)\n",
    "    \n",
    "# KNN = KNN(3,'vit','cosine')\n",
    "# KNN.print_answer()\n",
    "# print(KNN.train_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy  k    Metric Encoder Type\n",
      " 0.276667  7 manhattan          vit\n",
      "------------------------------\n",
      " Accuracy  k    Metric Encoder Type\n",
      " 0.276667  7 manhattan          vit\n",
      " 0.273333  7    cosine          vit\n",
      " 0.270000  9    cosine          vit\n",
      " 0.263333  9 euclidean          vit\n",
      " 0.260000  1 euclidean          vit\n",
      " 0.260000  9 manhattan          vit\n",
      " 0.256667  1 manhattan          vit\n",
      " 0.250000  5 manhattan          vit\n",
      " 0.246667  1    cosine          vit\n",
      " 0.246667  7 euclidean          vit\n",
      " 0.240000  5    cosine          vit\n",
      " 0.240000  7 manhattan       resnet\n",
      " 0.230000  5 euclidean          vit\n",
      " 0.223333  1 manhattan       resnet\n",
      " 0.220000  1    cosine       resnet\n",
      " 0.220000  3 euclidean          vit\n",
      " 0.220000  9 manhattan       resnet\n",
      " 0.213333  3 manhattan          vit\n",
      " 0.213333  3    cosine          vit\n",
      " 0.210000  5 manhattan       resnet\n"
     ]
    }
   ],
   "source": [
    "KNN = KNN(3,'vit','manhattan')\n",
    "K = [1,3,5,7,9]\n",
    "metric = ['manhattan','euclidean','cosine']\n",
    "encoder_type = ['vit','resnet']\n",
    "KNN.data_split(data)\n",
    "tuples = []\n",
    "for k in K:\n",
    "    for metric_type in metric:\n",
    "        for encoder in encoder_type:\n",
    "            KNN.set_encoder_type(encoder)\n",
    "            KNN.set_k(k)\n",
    "            KNN.set_metric(metric_type)\n",
    "            KNN.train(KNN.get_encoder_type())\n",
    "            F1_score, accuracy, precision, recall = KNN.evaluate(KNN.validate_embeddings, KNN.validate_labels)\n",
    "            tuples.append((accuracy,k,metric_type,encoder))\n",
    "\n",
    "sorted_tuples = sorted(tuples, key=lambda x: x[0], reverse=True)\n",
    "best_triplet = sorted_tuples[0]\n",
    "# print_data = [[' Best Accuracy',best_triplet[0]],['K',best_triplet[1]],['metric_type',best_triplet[2]],['encoder_type',best_triplet[3]]]\n",
    "# df = pd.DataFrame(print_data,columns=['Measure','Value'])\n",
    "# print(df)\n",
    "best_triplets = sorted_tuples[:1]\n",
    "df = pd.DataFrame(best_triplets, columns=['Best Accuracy', 'k', 'Metric', 'Encoder Type'])\n",
    "# Display the DataFrame without the default index column\n",
    "print(df.to_string(index=False))\n",
    "print('------------------------------')\n",
    "top_triplets = sorted_tuples[:20]\n",
    "# for rank, triplet in enumerate(best_triplets[:20], start=1):\n",
    "#     print(f\"Rank {rank}: k={triplet[1]}, encoder={triplet[2]}, distance metric={triplet[3]}, accuracy={triplet[0]}\")\n",
    "df = pd.DataFrame(top_triplets, columns=['Accuracy', 'k', 'Metric', 'Encoder Type'])\n",
    "# Display the DataFrame without the default index column\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
